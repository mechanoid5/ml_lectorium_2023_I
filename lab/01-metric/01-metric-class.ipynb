{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__лабораторная работа N1:__  базовые методы машинного обучения, метрический подход\n",
    "\n",
    "__часть 1:__ решение задачи классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__цель:__ изучить возможности \"классических\" методов машинного обучения    \n",
    "      на примере инструментов библиотеки scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__порядок выполнения:__ для каждого типа задачи\n",
    "1. получить/сгенерировать данные \n",
    "2. изучить/визуализировать данные\n",
    "3. применить к ним соответствующий задаче метод,   \n",
    "4. к результатам модели применить методы оценки  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выбираем и загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.datasets in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.datasets\n",
      "\n",
      "DESCRIPTION\n",
      "    The :mod:`sklearn.datasets` module includes utilities to load datasets,\n",
      "    including methods to load and fetch popular reference datasets. It also\n",
      "    features some artificial data generators.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _arff_parser\n",
      "    _base\n",
      "    _california_housing\n",
      "    _covtype\n",
      "    _kddcup99\n",
      "    _lfw\n",
      "    _olivetti_faces\n",
      "    _openml\n",
      "    _rcv1\n",
      "    _samples_generator\n",
      "    _species_distributions\n",
      "    _svmlight_format_fast\n",
      "    _svmlight_format_io\n",
      "    _twenty_newsgroups\n",
      "    data (package)\n",
      "    descr (package)\n",
      "    images (package)\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    clear_data_home(data_home=None)\n",
      "        Delete all the content of the data home cache.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            The path to scikit-learn data directory. If `None`, the default path\n",
      "            is `~/sklearn_learn_data`.\n",
      "    \n",
      "    dump_svmlight_file(X, y, f, *, zero_based=True, comment=None, query_id=None, multilabel=False)\n",
      "        Dump the dataset in svmlight / libsvm file format.\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Training vectors, where `n_samples` is the number of samples and\n",
      "            `n_features` is the number of features.\n",
      "        \n",
      "        y : {array-like, sparse matrix}, shape = [n_samples (, n_labels)]\n",
      "            Target values. Class labels must be an\n",
      "            integer or float, or array-like objects of integer or float for\n",
      "            multilabel classifications.\n",
      "        \n",
      "        f : str or file-like in binary mode\n",
      "            If string, specifies the path that will contain the data.\n",
      "            If file-like, data will be written to f. f should be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        zero_based : bool, default=True\n",
      "            Whether column indices should be written zero-based (True) or one-based\n",
      "            (False).\n",
      "        \n",
      "        comment : str, default=None\n",
      "            Comment to insert at the top of the file. This should be either a\n",
      "            Unicode string, which will be encoded as UTF-8, or an ASCII byte\n",
      "            string.\n",
      "            If a comment is given, then it will be preceded by one that identifies\n",
      "            the file as having been dumped by scikit-learn. Note that not all\n",
      "            tools grok comments in SVMlight files.\n",
      "        \n",
      "        query_id : array-like of shape (n_samples,), default=None\n",
      "            Array containing pairwise preference constraints (qid in svmlight\n",
      "            format).\n",
      "        \n",
      "        multilabel : bool, default=False\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html).\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter *multilabel* to support multilabel datasets.\n",
      "    \n",
      "    fetch_20newsgroups(*, data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True, return_X_y=False)\n",
      "        Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality               1\n",
      "        Features                  text\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify a download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : {'train', 'test', 'all'}, default='train'\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        categories : array-like, dtype=str, default=None\n",
      "            If None (default), load all the categories.\n",
      "            If not None, list of category names to load (other categories\n",
      "            ignored).\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        remove : tuple, default=()\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "            'headers' follows an exact standard; the other filters are not always\n",
      "            correct.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns `(data.data, data.target)` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : list of shape (n_samples,)\n",
      "                The data list to learn.\n",
      "            target: ndarray of shape (n_samples,)\n",
      "                The target labels.\n",
      "            filenames: list of shape (n_samples,)\n",
      "                The path to the location of the data.\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            target_names: list of shape (n_classes,)\n",
      "                The names of target classes.\n",
      "        \n",
      "        (data, target) : tuple if `return_X_y=True`\n",
      "            A tuple of two ndarrays. The first contains a 2D array of shape\n",
      "            (n_samples, n_classes) with each row representing one sample and each\n",
      "            column representing the features. The second array of shape\n",
      "            (n_samples,) contains the target samples.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "    \n",
      "    fetch_20newsgroups_vectorized(*, subset='train', remove=(), data_home=None, download_if_missing=True, return_X_y=False, normalize=True, as_frame=False)\n",
      "        Load and vectorize the 20 newsgroups dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        This is a convenience function; the transformation is done using the\n",
      "        default settings for\n",
      "        :class:`~sklearn.feature_extraction.text.CountVectorizer`. For more\n",
      "        advanced usage (stopword filtering, n-gram extraction, etc.), combine\n",
      "        fetch_20newsgroups with a custom\n",
      "        :class:`~sklearn.feature_extraction.text.CountVectorizer`,\n",
      "        :class:`~sklearn.feature_extraction.text.HashingVectorizer`,\n",
      "        :class:`~sklearn.feature_extraction.text.TfidfTransformer` or\n",
      "        :class:`~sklearn.feature_extraction.text.TfidfVectorizer`.\n",
      "        \n",
      "        The resulting counts are normalized using\n",
      "        :func:`sklearn.preprocessing.normalize` unless normalize is set to False.\n",
      "        \n",
      "        =================   ==========\n",
      "        Classes                     20\n",
      "        Samples total            18846\n",
      "        Dimensionality          130107\n",
      "        Features                  real\n",
      "        =================   ==========\n",
      "        \n",
      "        Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : {'train', 'test', 'all'}, default='train'\n",
      "            Select the dataset to load: 'train' for the training set, 'test'\n",
      "            for the test set, 'all' for both, with shuffled ordering.\n",
      "        \n",
      "        remove : tuple, default=()\n",
      "            May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "            these are kinds of text that will be detected and removed from the\n",
      "            newsgroup posts, preventing classifiers from overfitting on\n",
      "            metadata.\n",
      "        \n",
      "            'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "            ends of posts that look like signatures, and 'quotes' removes lines\n",
      "            that appear to be quoting another post.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify an download and cache folder for the datasets. If None,\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise an IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If True, normalizes each document's feature vector to unit norm using\n",
      "            :func:`sklearn.preprocessing.normalize`.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string, or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of\n",
      "            `target_columns`.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bunch : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data: {sparse matrix, dataframe} of shape (n_samples, n_features)\n",
      "                The input data matrix. If ``as_frame`` is `True`, ``data`` is\n",
      "                a pandas DataFrame with sparse columns.\n",
      "            target: {ndarray, series} of shape (n_samples,)\n",
      "                The target labels. If ``as_frame`` is `True`, ``target`` is a\n",
      "                pandas Series.\n",
      "            target_names: list of shape (n_classes,)\n",
      "                The names of target classes.\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            frame: dataframe of shape (n_samples, n_features + 1)\n",
      "                Only present when `as_frame=True`. Pandas DataFrame with ``data``\n",
      "                and ``target``.\n",
      "        \n",
      "                .. versionadded:: 0.24\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            `data` and `target` would be of the format defined in the `Bunch`\n",
      "            description above.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_california_housing(*, data_home=None, download_if_missing=True, return_X_y=False, as_frame=False)\n",
      "        Load the California housing dataset (regression).\n",
      "        \n",
      "        ==============   ==============\n",
      "        Samples total             20640\n",
      "        Dimensionality                8\n",
      "        Features                   real\n",
      "        Target           real 0.15 - 5.\n",
      "        ==============   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <california_housing_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target_columns.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray, shape (20640, 8)\n",
      "                Each row corresponding to the 8 feature values in order.\n",
      "                If ``as_frame`` is True, ``data`` is a pandas object.\n",
      "            target : numpy array of shape (20640,)\n",
      "                Each value corresponds to the average\n",
      "                house value in units of 100,000.\n",
      "                If ``as_frame`` is True, ``target`` is a pandas object.\n",
      "            feature_names : list of length 8\n",
      "                Array of ordered feature names used in the dataset.\n",
      "            DESCR : str\n",
      "                Description of the California housing dataset.\n",
      "            frame : pandas DataFrame\n",
      "                Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "                ``target``.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarray. The first containing a 2D array of\n",
      "            shape (n_samples, n_features) with each row representing one\n",
      "            sample and each column representing the features. The second\n",
      "            ndarray of shape (n_samples,) containing the target samples.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset consists of 20,640 samples and 9 features.\n",
      "    \n",
      "    fetch_covtype(*, data_home=None, download_if_missing=True, random_state=None, shuffle=False, return_X_y=False, as_frame=False)\n",
      "        Load the covertype dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ============\n",
      "        Classes                        7\n",
      "        Samples total             581012\n",
      "        Dimensionality                54\n",
      "        Features                     int\n",
      "        =================   ============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <covtype_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data.data, data.target)`` instead of a Bunch\n",
      "            object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is a pandas DataFrame or\n",
      "            Series depending on the number of target columns. If `return_X_y` is\n",
      "            True, then (`data`, `target`) will be pandas DataFrames or Series as\n",
      "            described below.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray of shape (581012, 54)\n",
      "                Each row corresponds to the 54 features in the dataset.\n",
      "            target : ndarray of shape (581012,)\n",
      "                Each value corresponds to one of\n",
      "                the 7 forest covertypes with values\n",
      "                ranging between 1 to 7.\n",
      "            frame : dataframe of shape (581012, 55)\n",
      "                Only present when `as_frame=True`. Contains `data` and `target`.\n",
      "            DESCR : str\n",
      "                Description of the forest covertype dataset.\n",
      "            feature_names : list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of the target columns.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarray. The first containing a 2D array of\n",
      "            shape (n_samples, n_features) with each row representing one\n",
      "            sample and each column representing the features. The second\n",
      "            ndarray of shape (n_samples,) containing the target samples.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_kddcup99(*, subset=None, data_home=None, shuffle=False, random_state=None, percent10=True, download_if_missing=True, return_X_y=False, as_frame=False)\n",
      "        Load the kddcup99 dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   ====================================\n",
      "        Classes                                               23\n",
      "        Samples total                                    4898431\n",
      "        Dimensionality                                        41\n",
      "        Features            discrete (int) or continuous (float)\n",
      "        =================   ====================================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <kddcup99_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : {'SA', 'SF', 'http', 'smtp'}, default=None\n",
      "            To return the corresponding classical subsets of kddcup 99.\n",
      "            If None, return the entire kddcup 99 dataset.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling and for\n",
      "            selection of abnormal samples if `subset='SA'`. Pass an int for\n",
      "            reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        percent10 : bool, default=True\n",
      "            Whether to load only 10 percent of the data.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If `True`, returns a pandas Dataframe for the ``data`` and ``target``\n",
      "            objects in the `Bunch` returned object; `Bunch` return object will also\n",
      "            have a ``frame`` member.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (494021, 41)\n",
      "                The data matrix to learn. If `as_frame=True`, `data` will be a\n",
      "                pandas DataFrame.\n",
      "            target : {ndarray, series} of shape (494021,)\n",
      "                The regression target for each sample. If `as_frame=True`, `target`\n",
      "                will be a pandas Series.\n",
      "            frame : dataframe of shape (494021, 42)\n",
      "                Only present when `as_frame=True`. Contains `data` and `target`.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            feature_names : list\n",
      "                The names of the dataset columns\n",
      "            target_names: list\n",
      "                The names of the target columns\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarray. The first containing a 2D array of\n",
      "            shape (n_samples, n_features) with each row representing one\n",
      "            sample and each column representing the features. The second\n",
      "            ndarray of shape (n_samples,) containing the target samples.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_lfw_pairs(*, subset='train', data_home=None, funneled=True, resize=0.5, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True)\n",
      "        Load the Labeled Faces in the Wild (LFW) pairs dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                   2\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        In the official `README.txt`_ this task is described as the\n",
      "        \"Restricted\" task.  As I am not sure as to implement the\n",
      "        \"Unrestricted\" variant correctly, I left it as unsupported for now.\n",
      "        \n",
      "          .. _`README.txt`: http://vis-www.cs.umass.edu/lfw/README.txt\n",
      "        \n",
      "        The original images are 250 x 250 pixels, but the default slice and resize\n",
      "        arguments reduce them to 62 x 47.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        subset : {'train', 'test', '10_folds'}, default='train'\n",
      "            Select the dataset to load: 'train' for the development training\n",
      "            set, 'test' for the development test set, and '10_folds' for the\n",
      "            official evaluation set that is meant to be used with a 10-folds\n",
      "            cross validation.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By\n",
      "            default all scikit-learn data is stored in '~/scikit_learn_data'\n",
      "            subfolders.\n",
      "        \n",
      "        funneled : bool, default=True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, default=0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        color : bool, default=False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : tuple of slice, default=(slice(70, 195), slice(78, 172))\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray of shape (2200, 5828). Shape depends on ``subset``.\n",
      "                Each row corresponds to 2 ravel'd face images\n",
      "                of original size 62 x 47 pixels.\n",
      "                Changing the ``slice_``, ``resize`` or ``subset`` parameters\n",
      "                will change the shape of the output.\n",
      "            pairs : ndarray of shape (2200, 2, 62, 47). Shape depends on ``subset``\n",
      "                Each row has 2 face images corresponding\n",
      "                to same or different person from the dataset\n",
      "                containing 5749 people. Changing the ``slice_``,\n",
      "                ``resize`` or ``subset`` parameters will change the shape of the\n",
      "                output.\n",
      "            target : numpy array of shape (2200,). Shape depends on ``subset``.\n",
      "                Labels associated to each pair of images.\n",
      "                The two label values being different persons or the same person.\n",
      "            target_names : numpy array of shape (2,)\n",
      "                Explains the target values of the target array.\n",
      "                0 corresponds to \"Different person\", 1 corresponds to \"same person\".\n",
      "            DESCR : str\n",
      "                Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "    \n",
      "    fetch_lfw_people(*, data_home=None, funneled=True, resize=0.5, min_faces_per_person=0, color=False, slice_=(slice(70, 195, None), slice(78, 172, None)), download_if_missing=True, return_X_y=False)\n",
      "        Load the Labeled Faces in the Wild (LFW) people dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =======================\n",
      "        Classes                                5749\n",
      "        Samples total                         13233\n",
      "        Dimensionality                         5828\n",
      "        Features            real, between 0 and 255\n",
      "        =================   =======================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <labeled_faces_in_the_wild_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        funneled : bool, default=True\n",
      "            Download and use the funneled variant of the dataset.\n",
      "        \n",
      "        resize : float, default=0.5\n",
      "            Ratio used to resize the each face picture.\n",
      "        \n",
      "        min_faces_per_person : int, default=None\n",
      "            The extracted dataset will only retain pictures of people that have at\n",
      "            least `min_faces_per_person` different pictures.\n",
      "        \n",
      "        color : bool, default=False\n",
      "            Keep the 3 RGB channels instead of averaging them to a single\n",
      "            gray level channel. If color is True the shape of the data has\n",
      "            one more dimension than the shape with color = False.\n",
      "        \n",
      "        slice_ : tuple of slice, default=(slice(70, 195), slice(78, 172))\n",
      "            Provide a custom 2D slice (height, width) to extract the\n",
      "            'interesting' part of the jpeg files and avoid use statistical\n",
      "            correlation from the background\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : numpy array of shape (13233, 2914)\n",
      "                Each row corresponds to a ravelled face image\n",
      "                of original size 62 x 47 pixels.\n",
      "                Changing the ``slice_`` or resize parameters will change the\n",
      "                shape of the output.\n",
      "            images : numpy array of shape (13233, 62, 47)\n",
      "                Each row is a face image corresponding to one of the 5749 people in\n",
      "                the dataset. Changing the ``slice_``\n",
      "                or resize parameters will change the shape of the output.\n",
      "            target : numpy array of shape (13233,)\n",
      "                Labels associated to each face image.\n",
      "                Those labels range from 0-5748 and correspond to the person IDs.\n",
      "            target_names : numpy array of shape (5749,)\n",
      "                Names of all persons in the dataset.\n",
      "                Position in array corresponds to the person ID in the target array.\n",
      "            DESCR : str\n",
      "                Description of the Labeled Faces in the Wild (LFW) dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_olivetti_faces(*, data_home=None, shuffle=False, random_state=0, download_if_missing=True, return_X_y=False)\n",
      "        Load the Olivetti faces data-set from AT&T (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                                40\n",
      "        Samples total                         400\n",
      "        Dimensionality                       4096\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <olivetti_faces_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            If True the order of the dataset is shuffled to avoid having\n",
      "            images of the same person grouped.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=0\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns `(data, target)` instead of a `Bunch` object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data: ndarray, shape (400, 4096)\n",
      "                Each row corresponds to a ravelled\n",
      "                face image of original size 64 x 64 pixels.\n",
      "            images : ndarray, shape (400, 64, 64)\n",
      "                Each row is a face image\n",
      "                corresponding to one of the 40 subjects of the dataset.\n",
      "            target : ndarray, shape (400,)\n",
      "                Labels associated to each face image.\n",
      "                Those labels are ranging from 0-39 and correspond to the\n",
      "                Subject IDs.\n",
      "            DESCR : str\n",
      "                Description of the modified Olivetti Faces Dataset.\n",
      "        \n",
      "        (data, target) : tuple if `return_X_y=True`\n",
      "            Tuple with the `data` and `target` objects described above.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "    \n",
      "    fetch_openml(name: Optional[str] = None, *, version: Union[str, int] = 'active', data_id: Optional[int] = None, data_home: Optional[str] = None, target_column: Union[str, List, NoneType] = 'default-target', cache: bool = True, return_X_y: bool = False, as_frame: Union[str, bool] = 'auto', n_retries: int = 3, delay: float = 1.0)\n",
      "        Fetch dataset from openml by name or dataset id.\n",
      "        \n",
      "        Datasets are uniquely identified by either an integer ID or by a\n",
      "        combination of name and version (i.e. there might be multiple\n",
      "        versions of the 'iris' dataset). Please give either name or data_id\n",
      "        (not both). In case a name is given, a version can also be\n",
      "        provided.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <openml>`.\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "        \n",
      "        .. note:: EXPERIMENTAL\n",
      "        \n",
      "            The API is experimental (particularly the return value structure),\n",
      "            and might have small backward-incompatible changes without notice\n",
      "            or warning in future releases.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        name : str, default=None\n",
      "            String identifier of the dataset. Note that OpenML can have multiple\n",
      "            datasets with the same name.\n",
      "        \n",
      "        version : int or 'active', default='active'\n",
      "            Version of the dataset. Can only be provided if also ``name`` is given.\n",
      "            If 'active' the oldest version that's still active is used. Since\n",
      "            there may be more than one active version of a dataset, and those\n",
      "            versions may fundamentally be different from one another, setting an\n",
      "            exact version is highly recommended.\n",
      "        \n",
      "        data_id : int, default=None\n",
      "            OpenML ID of the dataset. The most specific way of retrieving a\n",
      "            dataset. If data_id is not given, name (and potential version) are\n",
      "            used to obtain a dataset.\n",
      "        \n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the data sets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        target_column : str, list or None, default='default-target'\n",
      "            Specify the column name in the data to use as target. If\n",
      "            'default-target', the standard target column a stored on the server\n",
      "            is used. If ``None``, all columns are returned as data and the\n",
      "            target is ``None``. If list (of strings), all columns with these names\n",
      "            are returned as multi-target (Note: not all scikit-learn classifiers\n",
      "            can handle all types of multi-output combinations).\n",
      "        \n",
      "        cache : bool, default=True\n",
      "            Whether to cache the downloaded datasets into `data_home`.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` objects.\n",
      "        \n",
      "        as_frame : bool or 'auto', default='auto'\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target_columns.\n",
      "            The Bunch will contain a ``frame`` attribute with the target and the\n",
      "            data. If ``return_X_y`` is True, then ``(data, target)`` will be pandas\n",
      "            DataFrames or Series as describe above.\n",
      "        \n",
      "            If as_frame is 'auto', the data and target will be converted to\n",
      "            DataFrame or Series as if as_frame is set to True, unless the dataset\n",
      "            is stored in sparse format.\n",
      "        \n",
      "            .. versionchanged:: 0.24\n",
      "               The default value of `as_frame` changed from `False` to `'auto'`\n",
      "               in 0.24.\n",
      "        \n",
      "        n_retries : int, default=3\n",
      "            Number of retries when HTTP errors or network timeouts are encountered.\n",
      "            Error with status code 412 won't be retried as they represent OpenML\n",
      "            generic errors.\n",
      "        \n",
      "        delay : float, default=1.0\n",
      "            Number of seconds between retries.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        \n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : np.array, scipy.sparse.csr_matrix of floats, or pandas DataFrame\n",
      "                The feature matrix. Categorical features are encoded as ordinals.\n",
      "            target : np.array, pandas Series or DataFrame\n",
      "                The regression target or classification labels, if applicable.\n",
      "                Dtype is float if numeric, and object if categorical. If\n",
      "                ``as_frame`` is True, ``target`` is a pandas object.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            feature_names : list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of the target columns.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "        \n",
      "            categories : dict or None\n",
      "                Maps each categorical feature name to a list of values, such\n",
      "                that the value encoded as i is ith in the list. If ``as_frame``\n",
      "                is True, this is None.\n",
      "            details : dict\n",
      "                More metadata from OpenML.\n",
      "            frame : pandas DataFrame\n",
      "                Only present when `as_frame=True`. DataFrame with ``data`` and\n",
      "                ``target``.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "        \n",
      "            .. note:: EXPERIMENTAL\n",
      "        \n",
      "                This interface is **experimental** and subsequent releases may\n",
      "                change attributes without notice (although there should only be\n",
      "                minor changes to ``data`` and ``target``).\n",
      "        \n",
      "            Missing values in the 'data' are represented as NaN's. Missing values\n",
      "            in 'target' are represented as NaN's (numerical target) or None\n",
      "            (categorical target).\n",
      "    \n",
      "    fetch_rcv1(*, data_home=None, subset='all', download_if_missing=True, random_state=None, shuffle=False, return_X_y=False)\n",
      "        Load the RCV1 multilabel dataset (classification).\n",
      "        \n",
      "        Download it if necessary.\n",
      "        \n",
      "        Version: RCV1-v2, vectors, full sets, topics multilabels.\n",
      "        \n",
      "        =================   =====================\n",
      "        Classes                               103\n",
      "        Samples total                      804414\n",
      "        Dimensionality                      47236\n",
      "        Features            real, between 0 and 1\n",
      "        =================   =====================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <rcv1_dataset>`.\n",
      "        \n",
      "        .. versionadded:: 0.17\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        subset : {'train', 'test', 'all'}, default='all'\n",
      "            Select the dataset to load: 'train' for the training set\n",
      "            (23149 samples), 'test' for the test set (781265 samples),\n",
      "            'all' for both, with the training samples first if shuffle is False.\n",
      "            This follows the official LYRL2004 chronological split.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle dataset.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(dataset.data, dataset.target)`` instead of a Bunch\n",
      "            object. See below for more information about the `dataset.data` and\n",
      "            `dataset.target` object.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dataset : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object. Returned only if `return_X_y` is False.\n",
      "            `dataset` has the following attributes:\n",
      "        \n",
      "            - data : sparse matrix of shape (804414, 47236), dtype=np.float64\n",
      "                The array has 0.16% of non zero values. Will be of CSR format.\n",
      "            - target : sparse matrix of shape (804414, 103), dtype=np.uint8\n",
      "                Each sample has a value of 1 in its categories, and 0 in others.\n",
      "                The array has 3.15% of non zero values. Will be of CSR format.\n",
      "            - sample_id : ndarray of shape (804414,), dtype=np.uint32,\n",
      "                Identification number of each sample, as ordered in dataset.data.\n",
      "            - target_names : ndarray of shape (103,), dtype=object\n",
      "                Names of each target (RCV1 topics), as ordered in dataset.target.\n",
      "            - DESCR : str\n",
      "                Description of the RCV1 dataset.\n",
      "        \n",
      "        (data, target) : tuple\n",
      "            A tuple consisting of `dataset.data` and `dataset.target`, as\n",
      "            described above. Returned only if `return_X_y` is True.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "    fetch_species_distributions(*, data_home=None, download_if_missing=True)\n",
      "        Loader for species distribution dataset from Phillips et. al. (2006)\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            Specify another download and cache folder for the datasets. By default\n",
      "            all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "        \n",
      "        download_if_missing : bool, default=True\n",
      "            If False, raise a IOError if the data is not locally available\n",
      "            instead of trying to download the data from the source site.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            coverages : array, shape = [14, 1592, 1212]\n",
      "                These represent the 14 features measured\n",
      "                at each point of the map grid.\n",
      "                The latitude/longitude values for the grid are discussed below.\n",
      "                Missing data is represented by the value -9999.\n",
      "            train : record array, shape = (1624,)\n",
      "                The training points for the data.  Each point has three fields:\n",
      "        \n",
      "                - train['species'] is the species name\n",
      "                - train['dd long'] is the longitude, in degrees\n",
      "                - train['dd lat'] is the latitude, in degrees\n",
      "            test : record array, shape = (620,)\n",
      "                The test points for the data.  Same format as the training data.\n",
      "            Nx, Ny : integers\n",
      "                The number of longitudes (x) and latitudes (y) in the grid\n",
      "            x_left_lower_corner, y_left_lower_corner : floats\n",
      "                The (x,y) position of the lower-left corner, in degrees\n",
      "            grid_size : float\n",
      "                The spacing between points of the grid, in degrees\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        * `\"Maximum entropy modeling of species geographic distributions\"\n",
      "          <http://rob.schapire.net/papers/ecolmod.pdf>`_\n",
      "          S. J. Phillips, R. P. Anderson, R. E. Schapire - Ecological Modelling,\n",
      "          190:231-259, 2006.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        \n",
      "        This dataset represents the geographic distribution of species.\n",
      "        The dataset is provided by Phillips et. al. (2006).\n",
      "        \n",
      "        The two species are:\n",
      "        \n",
      "        - `\"Bradypus variegatus\"\n",
      "          <http://www.iucnredlist.org/details/3038/0>`_ ,\n",
      "          the Brown-throated Sloth.\n",
      "        \n",
      "        - `\"Microryzomys minutus\"\n",
      "          <http://www.iucnredlist.org/details/13408/0>`_ ,\n",
      "          also known as the Forest Small Rice Rat, a rodent that lives in Peru,\n",
      "          Colombia, Ecuador, Peru, and Venezuela.\n",
      "        \n",
      "        - For an example of using this dataset with scikit-learn, see\n",
      "          :ref:`examples/applications/plot_species_distribution_modeling.py\n",
      "          <sphx_glr_auto_examples_applications_plot_species_distribution_modeling.py>`.\n",
      "    \n",
      "    get_data_home(data_home=None) -> str\n",
      "        Return the path of the scikit-learn data directory.\n",
      "        \n",
      "        This folder is used by some large dataset loaders to avoid downloading the\n",
      "        data several times.\n",
      "        \n",
      "        By default the data directory is set to a folder named 'scikit_learn_data' in the\n",
      "        user home folder.\n",
      "        \n",
      "        Alternatively, it can be set by the 'SCIKIT_LEARN_DATA' environment\n",
      "        variable or programmatically by giving an explicit folder path. The '~'\n",
      "        symbol is expanded to the user home folder.\n",
      "        \n",
      "        If the folder does not already exist, it is automatically created.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data_home : str, default=None\n",
      "            The path to scikit-learn data directory. If `None`, the default path\n",
      "            is `~/sklearn_learn_data`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data_home: str\n",
      "            The path to scikit-learn data directory.\n",
      "    \n",
      "    load_boston(*, return_X_y=False)\n",
      "        DEPRECATED: `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "        \n",
      "        The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "        the documentation of this function for further details.\n",
      "        \n",
      "        The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "        dataset unless the purpose of the code is to study and educate about\n",
      "        ethical issues in data science and machine learning.\n",
      "        \n",
      "        In this special case, you can fetch the dataset from the original\n",
      "        source::\n",
      "        \n",
      "            import pandas as pd\n",
      "            import numpy as np\n",
      "        \n",
      "            data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "            raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "            data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "            target = raw_df.values[1::2, 2]\n",
      "        \n",
      "        Alternative datasets include the California housing dataset (i.e.\n",
      "        :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "        dataset. You can load the datasets as follows::\n",
      "        \n",
      "            from sklearn.datasets import fetch_california_housing\n",
      "            housing = fetch_california_housing()\n",
      "        \n",
      "        for the California housing dataset and::\n",
      "        \n",
      "            from sklearn.datasets import fetch_openml\n",
      "            housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "        \n",
      "        for the Ames housing dataset.\n",
      "        \n",
      "        Load and return the Boston house-prices dataset (regression).\n",
      "        \n",
      "        ==============   ==============\n",
      "        Samples total               506\n",
      "        Dimensionality               13\n",
      "        Features         real, positive\n",
      "        Targets           real 5. - 50.\n",
      "        ==============   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "        \n",
      "        .. warning::\n",
      "            The Boston housing prices dataset has an ethical problem: as\n",
      "            investigated in [1]_, the authors of this dataset engineered a\n",
      "            non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "            positive impact on house prices [2]_. Furthermore the goal of the\n",
      "            research that led to the creation of this dataset was to study the\n",
      "            impact of air quality but it did not give adequate demonstration of the\n",
      "            validity of this assumption.\n",
      "        \n",
      "            The scikit-learn maintainers therefore strongly discourage the use of\n",
      "            this dataset unless the purpose of the code is to study and educate\n",
      "            about ethical issues in data science and machine learning.\n",
      "        \n",
      "            In this special case, you can fetch the dataset from the original\n",
      "            source::\n",
      "        \n",
      "                import pandas as pd  # doctest: +SKIP\n",
      "                import numpy as np\n",
      "        \n",
      "                data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "                raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "                data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "                target = raw_df.values[1::2, 2]\n",
      "        \n",
      "            Alternative datasets include the California housing dataset [3]_\n",
      "            (i.e. :func:`~sklearn.datasets.fetch_california_housing`) and Ames\n",
      "            housing dataset [4]_. You can load the datasets as follows::\n",
      "        \n",
      "                from sklearn.datasets import fetch_california_housing\n",
      "                housing = fetch_california_housing()\n",
      "        \n",
      "            for the California housing dataset and::\n",
      "        \n",
      "                from sklearn.datasets import fetch_openml\n",
      "                housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "        \n",
      "            for the Ames housing dataset.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : ndarray of shape (506, 13)\n",
      "                The data matrix.\n",
      "            target : ndarray of shape (506,)\n",
      "                The regression target.\n",
      "            filename : str\n",
      "                The physical location of boston csv dataset.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            feature_names : ndarray\n",
      "                The names of features\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarrays. The first contains a 2D array of shape (506, 13)\n",
      "            with each row representing one sample and each column representing the features.\n",
      "            The second array of shape (506,) contains the target samples.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed a wrong data point at [445, 0].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Racist data destruction? M Carlisle,\n",
      "                <https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>`_\n",
      "        .. [2] `Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "               \"Hedonic housing prices and the demand for clean air.\"\n",
      "               Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "               <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>`_\n",
      "        .. [3] `California housing dataset\n",
      "                <https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset>`_\n",
      "        .. [4] `Ames housing dataset\n",
      "                <https://www.openml.org/d/42165>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import warnings\n",
      "        >>> from sklearn.datasets import load_boston\n",
      "        >>> with warnings.catch_warnings():\n",
      "        ...     # You should probably not use this dataset.\n",
      "        ...     warnings.filterwarnings(\"ignore\")\n",
      "        ...     X, y = load_boston(return_X_y=True)\n",
      "        >>> print(X.shape)\n",
      "        (506, 13)\n",
      "    \n",
      "    load_breast_cancer(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the breast cancer wisconsin dataset (classification).\n",
      "        \n",
      "        The breast cancer dataset is a classic and very easy binary classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          2\n",
      "        Samples per class    212(M),357(B)\n",
      "        Samples total                  569\n",
      "        Dimensionality                  30\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        The copy of UCI ML Breast Cancer Wisconsin (Diagnostic) dataset is\n",
      "        downloaded from:\n",
      "        https://goo.gl/U2Uwz2\n",
      "        \n",
      "        Read more in the :ref:`User Guide <breast_cancer_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (569, 30)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target : {ndarray, Series} of shape (569,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names : list\n",
      "                The names of the dataset columns.\n",
      "            target_names : list\n",
      "                The names of target classes.\n",
      "            frame : DataFrame of shape (569, 31)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            filename : str\n",
      "                The path to the location of the data.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarrays by default. The first contains a 2D ndarray of\n",
      "            shape (569, 30) with each row representing one sample and each column\n",
      "            representing the features. The second ndarray of shape (569,) contains\n",
      "            the target samples.  If `as_frame=True`, both arrays are pandas objects,\n",
      "            i.e. `X` a dataframe and `y` a series.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 50, and 85, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_breast_cancer\n",
      "        >>> data = load_breast_cancer()\n",
      "        >>> data.target[[10, 50, 85]]\n",
      "        array([0, 1, 0])\n",
      "        >>> list(data.target_names)\n",
      "        ['malignant', 'benign']\n",
      "    \n",
      "    load_diabetes(*, return_X_y=False, as_frame=False, scaled=True)\n",
      "        Load and return the diabetes dataset (regression).\n",
      "        \n",
      "        ==============   ==================\n",
      "        Samples total    442\n",
      "        Dimensionality   10\n",
      "        Features         real, -.2 < x < .2\n",
      "        Targets          integer 25 - 346\n",
      "        ==============   ==================\n",
      "        \n",
      "        .. note::\n",
      "           The meaning of each feature (i.e. `feature_names`) might be unclear\n",
      "           (especially for `ltg`) as the documentation of the original dataset is\n",
      "           not explicit. We provide information that seems correct in regard with\n",
      "           the scientific literature in this field of research.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <diabetes_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        scaled : bool, default=True\n",
      "            If True, the feature variables are mean centered and scaled by the\n",
      "            standard deviation times the square root of `n_samples`.\n",
      "            If False, raw data is returned for the feature variables.\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (442, 10)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (442,)\n",
      "                The regression target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            frame: DataFrame of shape (442, 11)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            data_filename: str\n",
      "                The path to the location of the data.\n",
      "            target_filename: str\n",
      "                The path to the location of the target.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            Returns a tuple of two ndarray of shape (n_samples, n_features)\n",
      "            A 2D array with each row representing one sample and each column\n",
      "            representing the features and/or target of a given sample.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_digits(*, n_class=10, return_X_y=False, as_frame=False)\n",
      "        Load and return the digits dataset (classification).\n",
      "        \n",
      "        Each datapoint is a 8x8 image of a digit.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                         10\n",
      "        Samples per class             ~180\n",
      "        Samples total                 1797\n",
      "        Dimensionality                  64\n",
      "        Features             integers 0-16\n",
      "        =================   ==============\n",
      "        \n",
      "        This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "        https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "        \n",
      "        Read more in the :ref:`User Guide <digits_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_class : int, default=10\n",
      "            The number of classes to return. Between 0 and 10.\n",
      "        \n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (1797, 64)\n",
      "                The flattened data matrix. If `as_frame=True`, `data` will be\n",
      "                a pandas DataFrame.\n",
      "            target: {ndarray, Series} of shape (1797,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "            frame: DataFrame of shape (1797, 65)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            images: {ndarray} of shape (1797, 8, 8)\n",
      "                The raw image data.\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarrays by default. The first contains a 2D ndarray of\n",
      "            shape (1797, 64) with each row representing one sample and each column\n",
      "            representing the features. The second ndarray of shape (1797) contains\n",
      "            the target samples.  If `as_frame=True`, both arrays are pandas objects,\n",
      "            i.e. `X` a dataframe and `y` a series.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images::\n",
      "        \n",
      "            >>> from sklearn.datasets import load_digits\n",
      "            >>> digits = load_digits()\n",
      "            >>> print(digits.data.shape)\n",
      "            (1797, 64)\n",
      "            >>> import matplotlib.pyplot as plt\n",
      "            >>> plt.gray()\n",
      "            >>> plt.matshow(digits.images[0])\n",
      "            <...>\n",
      "            >>> plt.show()\n",
      "    \n",
      "    load_files(container_path, *, description=None, categories=None, load_content=True, shuffle=True, encoding=None, decode_error='strict', random_state=0, allowed_extensions=None)\n",
      "        Load text files with categories as subfolder names.\n",
      "        \n",
      "        Individual samples are assumed to be files stored a two levels folder\n",
      "        structure such as the following:\n",
      "        \n",
      "            container_folder/\n",
      "                category_1_folder/\n",
      "                    file_1.txt\n",
      "                    file_2.txt\n",
      "                    ...\n",
      "                    file_42.txt\n",
      "                category_2_folder/\n",
      "                    file_43.txt\n",
      "                    file_44.txt\n",
      "                    ...\n",
      "        \n",
      "        The folder names are used as supervised signal label names. The individual\n",
      "        file names are not important.\n",
      "        \n",
      "        This function does not try to extract features into a numpy array or scipy\n",
      "        sparse matrix. In addition, if load_content is false it does not try to\n",
      "        load the files in memory.\n",
      "        \n",
      "        To use text files in a scikit-learn classification or clustering algorithm,\n",
      "        you will need to use the :mod`~sklearn.feature_extraction.text` module to\n",
      "        build a feature extraction transformer that suits your problem.\n",
      "        \n",
      "        If you set load_content=True, you should also specify the encoding of the\n",
      "        text using the 'encoding' parameter. For many modern text files, 'utf-8'\n",
      "        will be the correct encoding. If you leave encoding equal to None, then the\n",
      "        content will be made of bytes instead of Unicode, and you will not be able\n",
      "        to use most functions in :mod:`~sklearn.feature_extraction.text`.\n",
      "        \n",
      "        Similar feature extractors should be built for other kind of unstructured\n",
      "        data input such as images, audio, video, ...\n",
      "        \n",
      "        If you want files with a specific file extension (e.g. `.txt`) then you\n",
      "        can pass a list of those file extensions to `allowed_extensions`.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <datasets>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        container_path : str\n",
      "            Path to the main folder holding one subfolder per category.\n",
      "        \n",
      "        description : str, default=None\n",
      "            A paragraph describing the characteristic of the dataset: its source,\n",
      "            reference, etc.\n",
      "        \n",
      "        categories : list of str, default=None\n",
      "            If None (default), load all the categories. If not None, list of\n",
      "            category names to load (other categories ignored).\n",
      "        \n",
      "        load_content : bool, default=True\n",
      "            Whether to load or not the content of the different files. If true a\n",
      "            'data' attribute containing the text information is present in the data\n",
      "            structure returned. If not, a filenames attribute gives the path to the\n",
      "            files.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether or not to shuffle the data: might be important for models that\n",
      "            make the assumption that the samples are independent and identically\n",
      "            distributed (i.i.d.), such as stochastic gradient descent.\n",
      "        \n",
      "        encoding : str, default=None\n",
      "            If None, do not try to decode the content of the files (e.g. for images\n",
      "            or other non-text content). If not None, encoding to use to decode text\n",
      "            files to Unicode if load_content is True.\n",
      "        \n",
      "        decode_error : {'strict', 'ignore', 'replace'}, default='strict'\n",
      "            Instruction on what to do if a byte sequence is given to analyze that\n",
      "            contains characters not of the given `encoding`. Passed as keyword\n",
      "            argument 'errors' to bytes.decode.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=0\n",
      "            Determines random number generation for dataset shuffling. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        allowed_extensions : list of str, default=None\n",
      "            List of desired file extensions to filter the files to be loaded.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : list of str\n",
      "                Only present when `load_content=True`.\n",
      "                The raw text data to learn.\n",
      "            target : ndarray\n",
      "                The target labels (integer index).\n",
      "            target_names : list\n",
      "                The names of target classes.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "            filenames: ndarray\n",
      "                The filenames holding the dataset.\n",
      "    \n",
      "    load_iris(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the iris dataset (classification).\n",
      "        \n",
      "        The iris dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class               50\n",
      "        Samples total                  150\n",
      "        Dimensionality                   4\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        Read more in the :ref:`User Guide <iris_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object. See\n",
      "            below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (150, 4)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (150,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "            frame: DataFrame of shape (150, 5)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            filename: str\n",
      "                The path to the location of the data.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarray. The first containing a 2D array of shape\n",
      "            (n_samples, n_features) with each row representing one sample and\n",
      "            each column representing the features. The second ndarray of shape\n",
      "            (n_samples,) containing the target samples.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "            .. versionchanged:: 0.20\n",
      "                Fixed two wrong data points according to Fisher's paper.\n",
      "                The new version is the same as in R, but not as in the UCI\n",
      "                Machine Learning Repository.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 25, and 50, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_iris\n",
      "        >>> data = load_iris()\n",
      "        >>> data.target[[10, 25, 50]]\n",
      "        array([0, 0, 1])\n",
      "        >>> list(data.target_names)\n",
      "        ['setosa', 'versicolor', 'virginica']\n",
      "    \n",
      "    load_linnerud(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the physical exercise Linnerud dataset.\n",
      "        \n",
      "        This dataset is suitable for multi-output regression tasks.\n",
      "        \n",
      "        ==============   ============================\n",
      "        Samples total    20\n",
      "        Dimensionality   3 (for both data and target)\n",
      "        Features         integer\n",
      "        Targets          integer\n",
      "        ==============   ============================\n",
      "        \n",
      "        Read more in the :ref:`User Guide <linnerrud_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric, string or categorical). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (20, 3)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, dataframe} of shape (20, 3)\n",
      "                The regression targets. If `as_frame=True`, `target` will be\n",
      "                a pandas DataFrame.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of the target columns.\n",
      "            frame: DataFrame of shape (20, 6)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "            data_filename: str\n",
      "                The path to the location of the data.\n",
      "            target_filename: str\n",
      "                The path to the location of the target.\n",
      "        \n",
      "                .. versionadded:: 0.20\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            Returns a tuple of two ndarrays or dataframe of shape\n",
      "            `(20, 3)`. Each row represents one sample and each column represents the\n",
      "            features in `X` and a target in `y` of a given sample.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "    \n",
      "    load_sample_image(image_name)\n",
      "        Load the numpy array of a single sample image.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        image_name : {`china.jpg`, `flower.jpg`}\n",
      "            The name of the sample image loaded.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        img : 3D array\n",
      "            The image as a numpy array: height x width x color.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_image\n",
      "        >>> china = load_sample_image('china.jpg')   # doctest: +SKIP\n",
      "        >>> china.dtype                              # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> china.shape                              # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> flower = load_sample_image('flower.jpg') # doctest: +SKIP\n",
      "        >>> flower.dtype                             # doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "        >>> flower.shape                             # doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "    \n",
      "    load_sample_images()\n",
      "        Load sample images for image manipulation.\n",
      "        \n",
      "        Loads both, ``china`` and ``flower``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_images>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            images : list of ndarray of shape (427, 640, 3)\n",
      "                The two sample image.\n",
      "            filenames : list\n",
      "                The filenames for the images.\n",
      "            DESCR : str\n",
      "                The full description of the dataset.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To load the data and visualize the images:\n",
      "        \n",
      "        >>> from sklearn.datasets import load_sample_images\n",
      "        >>> dataset = load_sample_images()     #doctest: +SKIP\n",
      "        >>> len(dataset.images)                #doctest: +SKIP\n",
      "        2\n",
      "        >>> first_img_data = dataset.images[0] #doctest: +SKIP\n",
      "        >>> first_img_data.shape               #doctest: +SKIP\n",
      "        (427, 640, 3)\n",
      "        >>> first_img_data.dtype               #doctest: +SKIP\n",
      "        dtype('uint8')\n",
      "    \n",
      "    load_svmlight_file(f, *, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load datasets in the svmlight / libsvm format into sparse CSR matrix\n",
      "        \n",
      "        This format is a text-based format, with one sample per line. It does\n",
      "        not store zero valued features hence is suitable for sparse dataset.\n",
      "        \n",
      "        The first element of each line can be used to store a target variable\n",
      "        to predict.\n",
      "        \n",
      "        This format is used as the default format for both svmlight and the\n",
      "        libsvm command line programs.\n",
      "        \n",
      "        Parsing a text based source can be expensive. When repeatedly\n",
      "        working on the same dataset, it is recommended to wrap this\n",
      "        loader with joblib.Memory.cache to store a memmapped backup of the\n",
      "        CSR results of the first call and benefit from the near instantaneous\n",
      "        loading of memmapped structures for the subsequent calls.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        This implementation is written in Cython and is reasonably fast.\n",
      "        However, a faster API-compatible loader is also available at:\n",
      "        \n",
      "          https://github.com/mblondel/svmlight-loader\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f : str, file-like or int\n",
      "            (Path to) a file to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. A file-like or file descriptor will not be closed\n",
      "            by this function. A file-like object must be opened in binary mode.\n",
      "        \n",
      "        n_features : int, default=None\n",
      "            The number of features to use. If None, it will be inferred. This\n",
      "            argument is useful to load several files that are subsets of a\n",
      "            bigger sliced dataset: each subset might not have examples of\n",
      "            every feature, hence the inferred shape might vary from one\n",
      "            slice to another.\n",
      "            n_features is only required if ``offset`` or ``length`` are passed a\n",
      "            non-default value.\n",
      "        \n",
      "        dtype : numpy data type, default=np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : bool, default=False\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "        zero_based : bool or \"auto\", default=\"auto\"\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no ``offset`` or ``length`` is passed.\n",
      "            If ``offset`` or ``length`` are passed, the \"auto\" mode falls back\n",
      "            to ``zero_based=True`` to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : bool, default=False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : int, default=0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : int, default=-1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : scipy.sparse matrix of shape (n_samples, n_features)\n",
      "        \n",
      "        y : ndarray of shape (n_samples,), or, in the multilabel a list of\n",
      "            tuples of length n_samples.\n",
      "        \n",
      "        query_id : array of shape (n_samples,)\n",
      "           query_id for each sample. Only returned when query_id is set to\n",
      "           True.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        load_svmlight_files : Similar function for loading multiple files in this\n",
      "            format, enforcing the same number of features/columns on all of them.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        To use joblib.Memory to cache the svmlight file::\n",
      "        \n",
      "            from joblib import Memory\n",
      "            from .datasets import load_svmlight_file\n",
      "            mem = Memory(\"./mycache\")\n",
      "        \n",
      "            @mem.cache\n",
      "            def get_data():\n",
      "                data = load_svmlight_file(\"mysvmlightfile\")\n",
      "                return data[0], data[1]\n",
      "        \n",
      "            X, y = get_data()\n",
      "    \n",
      "    load_svmlight_files(files, *, n_features=None, dtype=<class 'numpy.float64'>, multilabel=False, zero_based='auto', query_id=False, offset=0, length=-1)\n",
      "        Load dataset from multiple files in SVMlight format\n",
      "        \n",
      "        This function is equivalent to mapping load_svmlight_file over a list of\n",
      "        files, except that the results are concatenated into a single, flat list\n",
      "        and the samples vectors are constrained to all have the same number of\n",
      "        features.\n",
      "        \n",
      "        In case the file contains a pairwise preference constraint (known\n",
      "        as \"qid\" in the svmlight format) these are ignored unless the\n",
      "        query_id parameter is set to True. These pairwise preference\n",
      "        constraints can be used to constraint the combination of samples\n",
      "        when using pairwise loss functions (as is the case in some\n",
      "        learning to rank problems) so that only pairs with the same\n",
      "        query_id value are considered.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        files : array-like, dtype=str, file-like or int\n",
      "            (Paths of) files to load. If a path ends in \".gz\" or \".bz2\", it will\n",
      "            be uncompressed on the fly. If an integer is passed, it is assumed to\n",
      "            be a file descriptor. File-likes and file descriptors will not be\n",
      "            closed by this function. File-like objects must be opened in binary\n",
      "            mode.\n",
      "        \n",
      "        n_features : int, default=None\n",
      "            The number of features to use. If None, it will be inferred from the\n",
      "            maximum column index occurring in any of the files.\n",
      "        \n",
      "            This can be set to a higher value than the actual number of features\n",
      "            in any of the input files, but setting it to a lower value will cause\n",
      "            an exception to be raised.\n",
      "        \n",
      "        dtype : numpy data type, default=np.float64\n",
      "            Data type of dataset to be loaded. This will be the data type of the\n",
      "            output numpy arrays ``X`` and ``y``.\n",
      "        \n",
      "        multilabel : bool, default=False\n",
      "            Samples may have several labels each (see\n",
      "            https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel.html)\n",
      "        \n",
      "        zero_based : bool or \"auto\", default=\"auto\"\n",
      "            Whether column indices in f are zero-based (True) or one-based\n",
      "            (False). If column indices are one-based, they are transformed to\n",
      "            zero-based to match Python/NumPy conventions.\n",
      "            If set to \"auto\", a heuristic check is applied to determine this from\n",
      "            the file contents. Both kinds of files occur \"in the wild\", but they\n",
      "            are unfortunately not self-identifying. Using \"auto\" or True should\n",
      "            always be safe when no offset or length is passed.\n",
      "            If offset or length are passed, the \"auto\" mode falls back\n",
      "            to zero_based=True to avoid having the heuristic check yield\n",
      "            inconsistent results on different segments of the file.\n",
      "        \n",
      "        query_id : bool, default=False\n",
      "            If True, will return the query_id array for each file.\n",
      "        \n",
      "        offset : int, default=0\n",
      "            Ignore the offset first bytes by seeking forward, then\n",
      "            discarding the following bytes up until the next new line\n",
      "            character.\n",
      "        \n",
      "        length : int, default=-1\n",
      "            If strictly positive, stop reading any new line of data once the\n",
      "            position in the file has reached the (offset + length) bytes threshold.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        [X1, y1, ..., Xn, yn]\n",
      "        where each (Xi, yi) pair is the result from load_svmlight_file(files[i]).\n",
      "        \n",
      "        If query_id is set to True, this will return instead [X1, y1, q1,\n",
      "        ..., Xn, yn, qn] where (Xi, yi, qi) is the result from\n",
      "        load_svmlight_file(files[i])\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When fitting a model to a matrix X_train and evaluating it against a\n",
      "        matrix X_test, it is essential that X_train and X_test have the same\n",
      "        number of features (X_train.shape[1] == X_test.shape[1]). This may not\n",
      "        be the case if you load the files individually with load_svmlight_file.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        load_svmlight_file\n",
      "    \n",
      "    load_wine(*, return_X_y=False, as_frame=False)\n",
      "        Load and return the wine dataset (classification).\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        The wine dataset is a classic and very easy multi-class classification\n",
      "        dataset.\n",
      "        \n",
      "        =================   ==============\n",
      "        Classes                          3\n",
      "        Samples per class        [59,71,48]\n",
      "        Samples total                  178\n",
      "        Dimensionality                  13\n",
      "        Features            real, positive\n",
      "        =================   ==============\n",
      "        \n",
      "        The copy of UCI ML Wine Data Set dataset is downloaded and modified to fit\n",
      "        standard format from:\n",
      "        https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "        \n",
      "        Read more in the :ref:`User Guide <wine_dataset>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        return_X_y : bool, default=False\n",
      "            If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "            See below for more information about the `data` and `target` object.\n",
      "        \n",
      "        as_frame : bool, default=False\n",
      "            If True, the data is a pandas DataFrame including columns with\n",
      "            appropriate dtypes (numeric). The target is\n",
      "            a pandas DataFrame or Series depending on the number of target columns.\n",
      "            If `return_X_y` is True, then (`data`, `target`) will be pandas\n",
      "            DataFrames or Series as described below.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : :class:`~sklearn.utils.Bunch`\n",
      "            Dictionary-like object, with the following attributes.\n",
      "        \n",
      "            data : {ndarray, dataframe} of shape (178, 13)\n",
      "                The data matrix. If `as_frame=True`, `data` will be a pandas\n",
      "                DataFrame.\n",
      "            target: {ndarray, Series} of shape (178,)\n",
      "                The classification target. If `as_frame=True`, `target` will be\n",
      "                a pandas Series.\n",
      "            feature_names: list\n",
      "                The names of the dataset columns.\n",
      "            target_names: list\n",
      "                The names of target classes.\n",
      "            frame: DataFrame of shape (178, 14)\n",
      "                Only present when `as_frame=True`. DataFrame with `data` and\n",
      "                `target`.\n",
      "        \n",
      "                .. versionadded:: 0.23\n",
      "            DESCR: str\n",
      "                The full description of the dataset.\n",
      "        \n",
      "        (data, target) : tuple if ``return_X_y`` is True\n",
      "            A tuple of two ndarrays by default. The first contains a 2D array of shape\n",
      "            (178, 13) with each row representing one sample and each column representing\n",
      "            the features. The second array of shape (178,) contains the target samples.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Let's say you are interested in the samples 10, 80, and 140, and want to\n",
      "        know their class name.\n",
      "        \n",
      "        >>> from sklearn.datasets import load_wine\n",
      "        >>> data = load_wine()\n",
      "        >>> data.target[[10, 80, 140]]\n",
      "        array([0, 1, 2])\n",
      "        >>> list(data.target_names)\n",
      "        ['class_0', 'class_1', 'class_2']\n",
      "    \n",
      "    make_biclusters(shape, n_clusters, *, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate a constant block diagonal structure array for biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : iterable of shape (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : int\n",
      "            The number of biclusters.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, default=10\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, default=100\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : ndarray of shape (n_clusters, X.shape[0])\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : ndarray of shape (n_clusters, X.shape[1])\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_checkerboard: Generate an array with block checkerboard structure for\n",
      "            biclustering.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] Dhillon, I. S. (2001, August). Co-clustering documents and\n",
      "            words using bipartite spectral graph partitioning. In Proceedings\n",
      "            of the seventh ACM SIGKDD international conference on Knowledge\n",
      "            discovery and data mining (pp. 269-274). ACM.\n",
      "    \n",
      "    make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0, center_box=(-10.0, 10.0), shuffle=True, random_state=None, return_centers=False)\n",
      "        Generate isotropic Gaussian blobs for clustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or array-like, default=100\n",
      "            If int, it is the total number of points equally divided among\n",
      "            clusters.\n",
      "            If array-like, each element of the sequence indicates\n",
      "            the number of samples per cluster.\n",
      "        \n",
      "            .. versionchanged:: v0.20\n",
      "                one can now pass an array-like to the ``n_samples`` parameter\n",
      "        \n",
      "        n_features : int, default=2\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        centers : int or ndarray of shape (n_centers, n_features), default=None\n",
      "            The number of centers to generate, or the fixed center locations.\n",
      "            If n_samples is an int and centers is None, 3 centers are generated.\n",
      "            If n_samples is array-like, centers must be\n",
      "            either None or an array of length equal to the length of n_samples.\n",
      "        \n",
      "        cluster_std : float or array-like of float, default=1.0\n",
      "            The standard deviation of the clusters.\n",
      "        \n",
      "        center_box : tuple of float (min, max), default=(-10.0, 10.0)\n",
      "            The bounding box for each cluster center when centers are\n",
      "            generated at random.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        return_centers : bool, default=False\n",
      "            If True, then return the centers of each cluster.\n",
      "        \n",
      "            .. versionadded:: 0.23\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels for cluster membership of each sample.\n",
      "        \n",
      "        centers : ndarray of shape (n_centers, n_features)\n",
      "            The centers of each cluster. Only returned if\n",
      "            ``return_centers=True``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_classification : A more intricate variant.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_blobs\n",
      "        >>> X, y = make_blobs(n_samples=10, centers=3, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 0, 1, 0, 2, 2, 2, 1, 1, 0])\n",
      "        >>> X, y = make_blobs(n_samples=[3, 3, 4], centers=None, n_features=2,\n",
      "        ...                   random_state=0)\n",
      "        >>> print(X.shape)\n",
      "        (10, 2)\n",
      "        >>> y\n",
      "        array([0, 1, 2, 0, 2, 2, 2, 1, 1, 0])\n",
      "    \n",
      "    make_checkerboard(shape, n_clusters, *, noise=0.0, minval=10, maxval=100, shuffle=True, random_state=None)\n",
      "        Generate an array with block checkerboard structure for biclustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : tuple of shape (n_rows, n_cols)\n",
      "            The shape of the result.\n",
      "        \n",
      "        n_clusters : int or array-like or shape (n_row_clusters, n_column_clusters)\n",
      "            The number of row and column clusters.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        minval : int, default=10\n",
      "            Minimum value of a bicluster.\n",
      "        \n",
      "        maxval : int, default=100\n",
      "            Maximum value of a bicluster.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape `shape`\n",
      "            The generated array.\n",
      "        \n",
      "        rows : ndarray of shape (n_clusters, X.shape[0])\n",
      "            The indicators for cluster membership of each row.\n",
      "        \n",
      "        cols : ndarray of shape (n_clusters, X.shape[1])\n",
      "            The indicators for cluster membership of each column.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_biclusters : Generate an array with constant block diagonal structure\n",
      "            for biclustering.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Kluger, Y., Basri, R., Chang, J. T., & Gerstein, M. (2003).\n",
      "            Spectral biclustering of microarray data: coclustering genes\n",
      "            and conditions. Genome research, 13(4), 703-716.\n",
      "    \n",
      "    make_circles(n_samples=100, *, shuffle=True, noise=None, random_state=None, factor=0.8)\n",
      "        Make a large circle containing a smaller circle in 2d.\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or tuple of shape (2,), dtype=int, default=100\n",
      "            If int, it is the total number of points generated.\n",
      "            For odd numbers, the inner circle will have one point more than the\n",
      "            outer circle.\n",
      "            If two-element tuple, number of points in outer circle and inner\n",
      "            circle.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Added two-element tuple.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : float, default=None\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        factor : float, default=.8\n",
      "            Scale factor between inner and outer circle in the range `(0, 1)`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 2)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
      "        Generate a random n-class classification problem.\n",
      "        \n",
      "        This initially creates clusters of points normally distributed (std=1)\n",
      "        about vertices of an ``n_informative``-dimensional hypercube with sides of\n",
      "        length ``2*class_sep`` and assigns an equal number of clusters to each\n",
      "        class. It introduces interdependence between these features and adds\n",
      "        various types of further noise to the data.\n",
      "        \n",
      "        Without shuffling, ``X`` horizontally stacks features in the following\n",
      "        order: the primary ``n_informative`` features, followed by ``n_redundant``\n",
      "        linear combinations of the informative features, followed by ``n_repeated``\n",
      "        duplicates, drawn randomly with replacement from the informative and\n",
      "        redundant features. The remaining features are filled with random noise.\n",
      "        Thus, without shuffling, all useful features are contained in the columns\n",
      "        ``X[:, :n_informative + n_redundant + n_repeated]``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=20\n",
      "            The total number of features. These comprise ``n_informative``\n",
      "            informative features, ``n_redundant`` redundant features,\n",
      "            ``n_repeated`` duplicated features and\n",
      "            ``n_features-n_informative-n_redundant-n_repeated`` useless features\n",
      "            drawn at random.\n",
      "        \n",
      "        n_informative : int, default=2\n",
      "            The number of informative features. Each class is composed of a number\n",
      "            of gaussian clusters each located around the vertices of a hypercube\n",
      "            in a subspace of dimension ``n_informative``. For each cluster,\n",
      "            informative features are drawn independently from  N(0, 1) and then\n",
      "            randomly linearly combined within each cluster in order to add\n",
      "            covariance. The clusters are then placed on the vertices of the\n",
      "            hypercube.\n",
      "        \n",
      "        n_redundant : int, default=2\n",
      "            The number of redundant features. These features are generated as\n",
      "            random linear combinations of the informative features.\n",
      "        \n",
      "        n_repeated : int, default=0\n",
      "            The number of duplicated features, drawn randomly from the informative\n",
      "            and the redundant features.\n",
      "        \n",
      "        n_classes : int, default=2\n",
      "            The number of classes (or labels) of the classification problem.\n",
      "        \n",
      "        n_clusters_per_class : int, default=2\n",
      "            The number of clusters per class.\n",
      "        \n",
      "        weights : array-like of shape (n_classes,) or (n_classes - 1,),              default=None\n",
      "            The proportions of samples assigned to each class. If None, then\n",
      "            classes are balanced. Note that if ``len(weights) == n_classes - 1``,\n",
      "            then the last class weight is automatically inferred.\n",
      "            More than ``n_samples`` samples may be returned if the sum of\n",
      "            ``weights`` exceeds 1. Note that the actual class proportions will\n",
      "            not exactly match ``weights`` when ``flip_y`` isn't 0.\n",
      "        \n",
      "        flip_y : float, default=0.01\n",
      "            The fraction of samples whose class is assigned randomly. Larger\n",
      "            values introduce noise in the labels and make the classification\n",
      "            task harder. Note that the default setting flip_y > 0 might lead\n",
      "            to less than ``n_classes`` in y in some cases.\n",
      "        \n",
      "        class_sep : float, default=1.0\n",
      "            The factor multiplying the hypercube size.  Larger values spread\n",
      "            out the clusters/classes and make the classification task easier.\n",
      "        \n",
      "        hypercube : bool, default=True\n",
      "            If True, the clusters are put on the vertices of a hypercube. If\n",
      "            False, the clusters are put on the vertices of a random polytope.\n",
      "        \n",
      "        shift : float, ndarray of shape (n_features,) or None, default=0.0\n",
      "            Shift features by the specified value. If None, then features\n",
      "            are shifted by a random value drawn in [-class_sep, class_sep].\n",
      "        \n",
      "        scale : float, ndarray of shape (n_features,) or None, default=1.0\n",
      "            Multiply features by the specified value. If None, then features\n",
      "            are scaled by a random value drawn in [1, 100]. Note that scaling\n",
      "            happens after shifting.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels for class membership of each sample.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_blobs : Simplified variant.\n",
      "        make_multilabel_classification : Unrelated generator for multilabel tasks.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is adapted from Guyon [1] and was designed to generate\n",
      "        the \"Madelon\" dataset.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
      "               selection benchmark\", 2003.\n",
      "    \n",
      "    make_friedman1(n_samples=100, n_features=10, *, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #1\" regression problem.\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are independent features uniformly distributed on the interval\n",
      "        [0, 1]. The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = 10 * sin(pi * X[:, 0] * X[:, 1]) + 20 * (X[:, 2] - 0.5) ** 2 + 10 * X[:, 3] + 5 * X[:, 4] + noise * N(0, 1).\n",
      "        \n",
      "        Out of the `n_features` features, only 5 are actually used to compute\n",
      "        `y`. The remaining features are independent of `y`.\n",
      "        \n",
      "        The number of features has to be >= 5.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=10\n",
      "            The number of features. Should be at least 5.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman2(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #2\" regression problem.\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = (X[:, 0] ** 2 + (X[:, 1] * X[:, 2]  - 1 / (X[:, 1] * X[:, 3])) ** 2) ** 0.5 + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 4)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_friedman3(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate the \"Friedman #3\" regression problem.\n",
      "        \n",
      "        This dataset is described in Friedman [1] and Breiman [2].\n",
      "        \n",
      "        Inputs `X` are 4 independent features uniformly distributed on the\n",
      "        intervals::\n",
      "        \n",
      "            0 <= X[:, 0] <= 100,\n",
      "            40 * pi <= X[:, 1] <= 560 * pi,\n",
      "            0 <= X[:, 2] <= 1,\n",
      "            1 <= X[:, 3] <= 11.\n",
      "        \n",
      "        The output `y` is created according to the formula::\n",
      "        \n",
      "            y(X) = arctan((X[:, 1] * X[:, 2] - 1 / (X[:, 1] * X[:, 3])) / X[:, 0]) + noise * N(0, 1).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset noise. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 4)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Friedman, \"Multivariate adaptive regression splines\", The Annals\n",
      "               of Statistics 19 (1), pages 1-67, 1991.\n",
      "        \n",
      "        .. [2] L. Breiman, \"Bagging predictors\", Machine Learning 24,\n",
      "               pages 123-140, 1996.\n",
      "    \n",
      "    make_gaussian_quantiles(*, mean=None, cov=1.0, n_samples=100, n_features=2, n_classes=3, shuffle=True, random_state=None)\n",
      "        Generate isotropic Gaussian and label samples by quantile.\n",
      "        \n",
      "        This classification dataset is constructed by taking a multi-dimensional\n",
      "        standard normal distribution and defining classes separated by nested\n",
      "        concentric multi-dimensional spheres such that roughly equal numbers of\n",
      "        samples are in each class (quantiles of the :math:`\\chi^2` distribution).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : ndarray of shape (n_features,), default=None\n",
      "            The mean of the multi-dimensional normal distribution.\n",
      "            If None then use the origin (0, 0, ...).\n",
      "        \n",
      "        cov : float, default=1.0\n",
      "            The covariance matrix will be this value times the unit matrix. This\n",
      "            dataset only produces symmetric normal distributions.\n",
      "        \n",
      "        n_samples : int, default=100\n",
      "            The total number of points equally divided among classes.\n",
      "        \n",
      "        n_features : int, default=2\n",
      "            The number of features for each sample.\n",
      "        \n",
      "        n_classes : int, default=3\n",
      "            The number of classes.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels for quantile membership of each sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The dataset is from Zhu et al [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class AdaBoost\", 2009.\n",
      "    \n",
      "    make_hastie_10_2(n_samples=12000, *, random_state=None)\n",
      "        Generate data for binary classification used in Hastie et al. 2009, Example 10.2.\n",
      "        \n",
      "        The ten features are standard independent Gaussian and\n",
      "        the target ``y`` is defined by::\n",
      "        \n",
      "          y[i] = 1 if np.sum(X[i] ** 2) > 9.34 else -1\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=12000\n",
      "            The number of samples.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 10)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_gaussian_quantiles : A generalization of this dataset approach.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical\n",
      "               Learning Ed. 2\", Springer, 2009.\n",
      "    \n",
      "    make_low_rank_matrix(n_samples=100, n_features=100, *, effective_rank=10, tail_strength=0.5, random_state=None)\n",
      "        Generate a mostly low rank matrix with bell-shaped singular values.\n",
      "        \n",
      "        Most of the variance can be explained by a bell-shaped curve of width\n",
      "        effective_rank: the low rank part of the singular values profile is::\n",
      "        \n",
      "            (1 - tail_strength) * exp(-1.0 * (i / effective_rank) ** 2)\n",
      "        \n",
      "        The remaining singular values' tail is fat, decreasing as::\n",
      "        \n",
      "            tail_strength * exp(-0.1 * i / effective_rank).\n",
      "        \n",
      "        The low rank part of the profile can be considered the structured\n",
      "        signal part of the data while the tail can be considered the noisy\n",
      "        part of the data that cannot be summarized by a low number of linear\n",
      "        components (singular vectors).\n",
      "        \n",
      "        This kind of singular profiles is often seen in practice, for instance:\n",
      "         - gray level pictures of faces\n",
      "         - TF-IDF vectors of text documents crawled from the web\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=100\n",
      "            The number of features.\n",
      "        \n",
      "        effective_rank : int, default=10\n",
      "            The approximate number of singular vectors required to explain most of\n",
      "            the data by linear combinations.\n",
      "        \n",
      "        tail_strength : float, default=0.5\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile. The value should be between 0 and 1.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The matrix.\n",
      "    \n",
      "    make_moons(n_samples=100, *, shuffle=True, noise=None, random_state=None)\n",
      "        Make two interleaving half circles.\n",
      "        \n",
      "        A simple toy dataset to visualize clustering and classification\n",
      "        algorithms. Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int or tuple of shape (2,), dtype=int, default=100\n",
      "            If int, the total number of points generated.\n",
      "            If two-element tuple, number of points in each of two moons.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Added two-element tuple.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether to shuffle the samples.\n",
      "        \n",
      "        noise : float, default=None\n",
      "            Standard deviation of Gaussian noise added to the data.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset shuffling and noise.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 2)\n",
      "            The generated samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The integer labels (0 or 1) for class membership of each sample.\n",
      "    \n",
      "    make_multilabel_classification(n_samples=100, n_features=20, *, n_classes=5, n_labels=2, length=50, allow_unlabeled=True, sparse=False, return_indicator='dense', return_distributions=False, random_state=None)\n",
      "        Generate a random multilabel classification problem.\n",
      "        \n",
      "        For each sample, the generative process is:\n",
      "            - pick the number of labels: n ~ Poisson(n_labels)\n",
      "            - n times, choose a class c: c ~ Multinomial(theta)\n",
      "            - pick the document length: k ~ Poisson(length)\n",
      "            - k times, choose a word: w ~ Multinomial(theta_c)\n",
      "        \n",
      "        In the above process, rejection sampling is used to make sure that\n",
      "        n is never zero or more than `n_classes`, and that the document length\n",
      "        is never zero. Likewise, we reject classes which have already been chosen.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=20\n",
      "            The total number of features.\n",
      "        \n",
      "        n_classes : int, default=5\n",
      "            The number of classes of the classification problem.\n",
      "        \n",
      "        n_labels : int, default=2\n",
      "            The average number of labels per instance. More precisely, the number\n",
      "            of labels per sample is drawn from a Poisson distribution with\n",
      "            ``n_labels`` as its expected value, but samples are bounded (using\n",
      "            rejection sampling) by ``n_classes``, and must be nonzero if\n",
      "            ``allow_unlabeled`` is False.\n",
      "        \n",
      "        length : int, default=50\n",
      "            The sum of the features (number of words if documents) is drawn from\n",
      "            a Poisson distribution with this expected value.\n",
      "        \n",
      "        allow_unlabeled : bool, default=True\n",
      "            If ``True``, some instances might not belong to any class.\n",
      "        \n",
      "        sparse : bool, default=False\n",
      "            If ``True``, return a sparse feature matrix.\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter to allow *sparse* output.\n",
      "        \n",
      "        return_indicator : {'dense', 'sparse'} or False, default='dense'\n",
      "            If ``'dense'`` return ``Y`` in the dense binary indicator format. If\n",
      "            ``'sparse'`` return ``Y`` in the sparse binary indicator format.\n",
      "            ``False`` returns a list of lists of labels.\n",
      "        \n",
      "        return_distributions : bool, default=False\n",
      "            If ``True``, return the prior class probability and conditional\n",
      "            probabilities of features given classes, from which the data was\n",
      "            drawn.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The generated samples.\n",
      "        \n",
      "        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "            The label sets. Sparse matrix should be of CSR format.\n",
      "        \n",
      "        p_c : ndarray of shape (n_classes,)\n",
      "            The probability of each class being drawn. Only returned if\n",
      "            ``return_distributions=True``.\n",
      "        \n",
      "        p_w_c : ndarray of shape (n_features, n_classes)\n",
      "            The probability of each feature being drawn given each class.\n",
      "            Only returned if ``return_distributions=True``.\n",
      "    \n",
      "    make_regression(n_samples=100, n_features=100, *, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)\n",
      "        Generate a random regression problem.\n",
      "        \n",
      "        The input set can either be well conditioned (by default) or have a low\n",
      "        rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
      "        more details.\n",
      "        \n",
      "        The output is generated by applying a (potentially biased) random linear\n",
      "        regression model with `n_informative` nonzero regressors to the previously\n",
      "        generated input and some gaussian centered noise with some adjustable\n",
      "        scale.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=100\n",
      "            The number of features.\n",
      "        \n",
      "        n_informative : int, default=10\n",
      "            The number of informative features, i.e., the number of features used\n",
      "            to build the linear model used to generate the output.\n",
      "        \n",
      "        n_targets : int, default=1\n",
      "            The number of regression targets, i.e., the dimension of the y output\n",
      "            vector associated with a sample. By default, the output is a scalar.\n",
      "        \n",
      "        bias : float, default=0.0\n",
      "            The bias term in the underlying linear model.\n",
      "        \n",
      "        effective_rank : int, default=None\n",
      "            If not None:\n",
      "                The approximate number of singular vectors required to explain most\n",
      "                of the input data by linear combinations. Using this kind of\n",
      "                singular spectrum in the input allows the generator to reproduce\n",
      "                the correlations often observed in practice.\n",
      "            If None:\n",
      "                The input set is well conditioned, centered and gaussian with\n",
      "                unit variance.\n",
      "        \n",
      "        tail_strength : float, default=0.5\n",
      "            The relative importance of the fat noisy tail of the singular values\n",
      "            profile if `effective_rank` is not None. When a float, it should be\n",
      "            between 0 and 1.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise applied to the output.\n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Shuffle the samples and the features.\n",
      "        \n",
      "        coef : bool, default=False\n",
      "            If True, the coefficients of the underlying linear model are returned.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "            The output values.\n",
      "        \n",
      "        coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
      "            The coefficient of the underlying linear model. It is returned only if\n",
      "            coef is True.\n",
      "    \n",
      "    make_s_curve(n_samples=100, *, noise=0.0, random_state=None)\n",
      "        Generate an S curve dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of sample points on the S curve.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 3)\n",
      "            The points.\n",
      "        \n",
      "        t : ndarray of shape (n_samples,)\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "    \n",
      "    make_sparse_coded_signal(n_samples, *, n_components, n_features, n_nonzero_coefs, random_state=None, data_transposed='warn')\n",
      "        Generate a signal as a sparse combination of dictionary elements.\n",
      "        \n",
      "        Returns a matrix Y = DX, such that D is (n_features, n_components),\n",
      "        X is (n_components, n_samples) and each column of X has exactly\n",
      "        n_nonzero_coefs non-zero elements.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int\n",
      "            Number of samples to generate.\n",
      "        \n",
      "        n_components : int\n",
      "            Number of components in the dictionary.\n",
      "        \n",
      "        n_features : int\n",
      "            Number of features of the dataset to generate.\n",
      "        \n",
      "        n_nonzero_coefs : int\n",
      "            Number of active (non-zero) coefficients in each sample.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        data_transposed : bool, default=True\n",
      "            By default, Y, D and X are transposed.\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        data : ndarray of shape (n_features, n_samples) or (n_samples, n_features)\n",
      "            The encoded signal (Y). The shape is `(n_samples, n_features)` if\n",
      "            `data_transposed` is False, otherwise it's `(n_features, n_samples)`.\n",
      "        \n",
      "        dictionary : ndarray of shape (n_features, n_components) or             (n_components, n_features)\n",
      "            The dictionary with normalized components (D). The shape is\n",
      "            `(n_components, n_features)` if `data_transposed` is False, otherwise it's\n",
      "            `(n_features, n_components)`.\n",
      "        \n",
      "        code : ndarray of shape (n_components, n_samples) or (n_samples, n_components)\n",
      "            The sparse code such that each column of this matrix has exactly\n",
      "            n_nonzero_coefs non-zero items (X). The shape is `(n_samples, n_components)`\n",
      "            if `data_transposed` is False, otherwise it's `(n_components, n_samples)`.\n",
      "    \n",
      "    make_sparse_spd_matrix(dim=1, *, alpha=0.95, norm_diag=False, smallest_coef=0.1, largest_coef=0.9, random_state=None)\n",
      "        Generate a sparse symmetric definite positive matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dim : int, default=1\n",
      "            The size of the random matrix to generate.\n",
      "        \n",
      "        alpha : float, default=0.95\n",
      "            The probability that a coefficient is zero (see notes). Larger values\n",
      "            enforce more sparsity. The value should be in the range 0 and 1.\n",
      "        \n",
      "        norm_diag : bool, default=False\n",
      "            Whether to normalize the output matrix to make the leading diagonal\n",
      "            elements all 1.\n",
      "        \n",
      "        smallest_coef : float, default=0.1\n",
      "            The value of the smallest coefficient between 0 and 1.\n",
      "        \n",
      "        largest_coef : float, default=0.9\n",
      "            The value of the largest coefficient between 0 and 1.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        prec : sparse matrix of shape (dim, dim)\n",
      "            The generated matrix.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_spd_matrix : Generate a random symmetric, positive-definite matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sparsity is actually imposed on the cholesky factor of the matrix.\n",
      "        Thus alpha does not translate directly into the filling fraction of\n",
      "        the matrix itself.\n",
      "    \n",
      "    make_sparse_uncorrelated(n_samples=100, n_features=10, *, random_state=None)\n",
      "        Generate a random regression problem with sparse uncorrelated design.\n",
      "        \n",
      "        This dataset is described in Celeux et al [1]. as::\n",
      "        \n",
      "            X ~ N(0, 1)\n",
      "            y(X) = X[:, 0] + 2 * X[:, 1] - 2 * X[:, 2] - 1.5 * X[:, 3]\n",
      "        \n",
      "        Only the first 4 features are informative. The remaining features are\n",
      "        useless.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of samples.\n",
      "        \n",
      "        n_features : int, default=10\n",
      "            The number of features.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, n_features)\n",
      "            The input samples.\n",
      "        \n",
      "        y : ndarray of shape (n_samples,)\n",
      "            The output values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert,\n",
      "               \"Regularization in regression: comparing Bayesian and frequentist\n",
      "               methods in a poorly informative situation\", 2009.\n",
      "    \n",
      "    make_spd_matrix(n_dim, *, random_state=None)\n",
      "        Generate a random symmetric, positive-definite matrix.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_dim : int\n",
      "            The matrix dimension.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_dim, n_dim)\n",
      "            The random symmetric, positive-definite matrix.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        make_sparse_spd_matrix: Generate a sparse symmetric definite positive matrix.\n",
      "    \n",
      "    make_swiss_roll(n_samples=100, *, noise=0.0, random_state=None, hole=False)\n",
      "        Generate a swiss roll dataset.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <sample_generators>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n_samples : int, default=100\n",
      "            The number of sample points on the Swiss Roll.\n",
      "        \n",
      "        noise : float, default=0.0\n",
      "            The standard deviation of the gaussian noise.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for dataset creation. Pass an int\n",
      "            for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        hole : bool, default=False\n",
      "            If True generates the swiss roll with hole dataset.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X : ndarray of shape (n_samples, 3)\n",
      "            The points.\n",
      "        \n",
      "        t : ndarray of shape (n_samples,)\n",
      "            The univariate position of the sample according to the main dimension\n",
      "            of the points in the manifold.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm is from Marsland [1].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] S. Marsland, \"Machine Learning: An Algorithmic Perspective\", 2nd edition,\n",
      "               Chapter 6, 2014.\n",
      "               https://homepages.ecs.vuw.ac.nz/~marslast/Code/Ch6/lle.py\n",
      "\n",
      "DATA\n",
      "    __all__ = ['clear_data_home', 'dump_svmlight_file', 'fetch_20newsgroup...\n",
      "\n",
      "FILE\n",
      "    /opt/venv/jupyter_1/lib/python3.10/site-packages/sklearn/datasets/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "help(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбираем один из вариантов\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# https://archive.ics.uci.edu\n",
    "# https://www.openml.org/search?type=data\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# help(fetch_openml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## выделить тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загружаем и обучаем модель классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
      " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |  \n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, default=5\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
      " |      Weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, default=30\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : int, default=2\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : str or callable, default='minkowski'\n",
      " |      Metric to use for distance computation. Default is \"minkowski\", which\n",
      " |      results in the standard Euclidean distance when p = 2. See the\n",
      " |      documentation of `scipy.spatial.distance\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
      " |      the metrics listed in\n",
      " |      :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
      " |      values.\n",
      " |  \n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square during fit. X may be a :term:`sparse graph`, in which\n",
      " |      case only \"nonzero\" elements may be considered neighbors.\n",
      " |  \n",
      " |      If metric is a callable function, it takes two arrays representing 1D\n",
      " |      vectors as inputs and must return one value indicating the distance\n",
      " |      between those vectors. This works for Scipy's metrics, but is less\n",
      " |      efficient than passing the metric name as a string.\n",
      " |  \n",
      " |  metric_params : dict, default=None\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      Class labels known to the classifier\n",
      " |  \n",
      " |  effective_metric_ : str or callble\n",
      " |      The distance metric used. It will be same as the `metric` parameter\n",
      " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      " |      'minkowski' and `p` parameter set to 2.\n",
      " |  \n",
      " |  effective_metric_params_ : dict\n",
      " |      Additional keyword arguments for the metric function. For most metrics\n",
      " |      will be same with `metric_params` parameter, but may also contain the\n",
      " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
      " |      'minkowski'.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_fit_ : int\n",
      " |      Number of samples in the fitted data.\n",
      " |  \n",
      " |  outputs_2d_ : bool\n",
      " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      " |      otherwise True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y)\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.666... 0.333...]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors._base.KNeighborsMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.neighbors._base.NeighborsBase\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : KNeighborsClassifier\n",
      " |          The fitted k-nearest neighbors classifier.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Find the K-neighbors of a point.\n",
      " |      \n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors required for each sample. The default is the\n",
      " |          value passed to the constructor.\n",
      " |      \n",
      " |      return_distance : bool, default=True\n",
      " |          Whether or not to return the distances.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True.\n",
      " |      \n",
      " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NearestNeighbors\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples)\n",
      " |      NearestNeighbors(n_neighbors=1)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False)\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |          For ``metric='precomputed'`` the shape should be\n",
      " |          (n_queries, n_indexed). Otherwise the shape should be\n",
      " |          (n_queries, n_features).\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors for each sample. The default is the value\n",
      " |          passed to the constructor.\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are distances between points, type of distance\n",
      " |          depends on the selected metric parameter in\n",
      " |          NearestNeighbors class.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
      " |          `n_samples_fit` is the number of samples in the fitted data.\n",
      " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
      " |          The matrix is of CSR format.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
      " |          of Neighbors for points in X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X)\n",
      " |      NearestNeighbors(n_neighbors=2)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "help(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## оценка результатов классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # количество ошибок\n",
    "from sklearn.metrics import classification_report # метрики качества\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.594px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
